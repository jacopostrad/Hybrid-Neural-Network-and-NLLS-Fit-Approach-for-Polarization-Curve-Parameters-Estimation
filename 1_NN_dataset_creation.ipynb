{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfeb6a40",
   "metadata": {},
   "source": [
    "# Polarization Curve Analytical Modeling\n",
    "\n",
    "For the analytical modeling, the following equation was considered:\n",
    "\n",
    "$$\n",
    "E(i) = E_0 - b \\cdot \\ln \\left[ \\frac{1}{2} \\left( \\frac{i}{i_0} + \\sqrt{\\left(\\frac{i}{i_0}\\right)^2 + 4} \\right) \\right] - R \\cdot i + \\frac{1}{i - i_L}\n",
    "$$\n",
    "\n",
    "where $i_L$ and $i_0$ are the limiting and exchange current densities, respectively, $R$ is the system's ohmic resistance, $E_0$ is the equilibrium potential, and $b$ is the Tafel slope. \n",
    "\n",
    "This equation expresses the voltage losses in terms of overpotential starting from the equilibrium potential. In order, the terms represent: \n",
    "\n",
    "- **Kinetic or activation loss:** described by the Butler-Volmer equation (or Tafel form in this case),\n",
    "- **Ohmic loss:** due to material resistance,\n",
    "- **Mass transport loss:** due to the limited supply of reactants at the electrode surface, leading to concentration gradients in the electrolyte or near the electrode interface. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2f8a3",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6428a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90633c71",
   "metadata": {},
   "source": [
    "# Creation of simulated curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51d218",
   "metadata": {},
   "source": [
    "Choose number of values per parameter and number of points per curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c938775",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 12\n",
    "\n",
    "n_points = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b11abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "E0_min = 1.2631     #V\n",
    "E0_max = 1.5056     #V\n",
    "\n",
    "b_min = 28.78       #mV/dec\n",
    "b_max = 88          #mV/dec\n",
    "\n",
    "i0_min = 0.38       # μA/cm²\n",
    "i0_max = 705.22     # μA/cm²\n",
    "\n",
    "R_min = 0.69        #Ω·cm²\n",
    "R_max = 21.14       #Ω·cm²\n",
    "\n",
    "iL_min = 42.117     #mA/cm²\n",
    "iL_max = 570.699    #mA/cm²\n",
    "\n",
    "# Rescale for the function --> all the terms in [V]\n",
    "E0_min_real = E0_min    #V\n",
    "E0_max_real = E0_max    #V\n",
    "\n",
    "b_min_real = b_min / (1000 * np.log(10))    #V\n",
    "b_max_real = b_max / (1000 * np.log(10))    #V\n",
    "\n",
    "i0_min_real = i0_min / 1000     #mA/cm²\n",
    "i0_max_real = i0_max / 1000     #mA/cm²\n",
    "\n",
    "R_min_real = R_min / 1000       #kΩ·cm²\n",
    "R_max_real = R_max / 1000       #kΩ·cm²\n",
    "\n",
    "iL_min_real = iL_min    #mA/cm²\n",
    "iL_max_real = iL_max    #mA/cm²\n",
    "\n",
    "E0_range = np.linspace(E0_min_real, E0_max_real, n_val)\n",
    "b_range = np.linspace(b_min_real, b_max_real, n_val)\n",
    "i0_range = np.logspace(np.log10(i0_min_real), np.log10(i0_max_real), n_val)\n",
    "R_range = np.logspace(np.log10(R_min_real), np.log10(R_max_real), n_val)\n",
    "iL_range = np.logspace(np.log10(iL_min), np.log10(iL_max), n_val)\n",
    "file_name = 'params'\n",
    "\n",
    "n_params = len(E0_range) * len(b_range) * len(i0_range) * len(R_range) * len(iL_range)\n",
    "curves = np.full((n_params, n_points, 2), np.nan)\n",
    "params = np.full((n_params, 5), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0490501",
   "metadata": {},
   "source": [
    "Define the analytic function of the polarization curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4828aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(i, E0, b, i0, R, iL):\n",
    "    \"\"\"\n",
    "    Calculate E(i) based on the given parameters with specific units.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Current density (mA/cm²)\n",
    "    - E0: Standard potential (V)\n",
    "    - b: Tafel slope (V)\n",
    "    - i0: Exchange current density (mA/cm²)\n",
    "    - R: Resistance (kOhm·cm²)\n",
    "    - iL: Limiting current density (mA/cm²)\n",
    "\n",
    "    Returns:\n",
    "    - E: The calculated potential (V)\n",
    "    \"\"\"\n",
    "    \n",
    "    E_tot = E0 - b * np.log(0.5 * ((i / i0) + np.sqrt((i / i0)**2 + 4))) - R * i + 1 / (i - iL)\n",
    "\n",
    "    return E_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f82d3b",
   "metadata": {},
   "source": [
    "Curves creation and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "curves = np.full((len(E0_range) * len(b_range) * len(i0_range) * len(R_range) * len(iL_range), n_points, 2), np.nan)\n",
    "params = np.full((curves.shape[0], 5), np.nan)\n",
    "\n",
    "for E0 in E0_range:\n",
    "    for b in b_range:\n",
    "        for i0 in i0_range:\n",
    "            for R in R_range:\n",
    "                for iL in iL_range:\n",
    "\n",
    "                    # Initial i_max (93% of iL)\n",
    "                    i_max = 0.93 * iL  \n",
    "\n",
    "                    # Construction of current points\n",
    "                    if i_max <= 20:\n",
    "                        # Only range 0–i_max with step 1\n",
    "                        i_values = np.arange(0, i_max + 1, 1)\n",
    "                    else:\n",
    "                        # First range: 0–20 with step 1 (21 points)\n",
    "                        i_dense = np.arange(0, 21, 1)\n",
    "\n",
    "                        # Number of remaining points to complete n_points\n",
    "                        n_sparse = n_points - len(i_dense)\n",
    "\n",
    "                        # Second interval: from 20 (excluded) to i_max\n",
    "                        if n_sparse > 0:\n",
    "                            i_sparse = np.linspace(20, i_max, n_sparse + 1, endpoint=True)[1:]  # exclude 20\n",
    "                            i_values = np.concatenate((i_dense, i_sparse))\n",
    "                        else:\n",
    "                            i_values = i_dense  # in case n_points <= 21\n",
    "\n",
    "                    # Initial curve computation\n",
    "                    E_values = E(i_values, E0, b, i0, R, iL)\n",
    "\n",
    "                    # If the curve drops below 0.2 V → find i such that E(i) = 0.2\n",
    "                    if np.any(E_values < 0.2):\n",
    "                        E_func = lambda i: E(i, E0, b, i0, R, iL) - 0.2\n",
    "                        initial_guess = iL - 1e-4\n",
    "                        try:\n",
    "                            i_target = fsolve(E_func, initial_guess)[0]\n",
    "                            i_max = i_target\n",
    "                        except Exception as e:\n",
    "                            print(f\"Warning: i for E=0.2 not found, using original curve (idx={idx})\")\n",
    "\n",
    "                        # Rebuild point distribution using the same logic\n",
    "                        if i_max <= 20:\n",
    "                            i_values = np.arange(0, i_max + 1, 1)\n",
    "                        else:\n",
    "                            i_dense = np.arange(0, 21, 1)\n",
    "                            n_sparse = n_points - len(i_dense)\n",
    "                            if n_sparse > 0:\n",
    "                                i_sparse = np.linspace(20, i_max, n_sparse + 1, endpoint=True)[1:]\n",
    "                                i_values = np.concatenate((i_dense, i_sparse))\n",
    "                            else:\n",
    "                                i_values = i_dense\n",
    "\n",
    "                        # Recompute the curve up to E = 0.2\n",
    "                        E_values = E(i_values, E0, b, i0, R, iL)\n",
    "\n",
    "                    # Final storage\n",
    "                    curves[idx, :, 0] = i_values\n",
    "                    curves[idx, :, 1] = E_values\n",
    "                    params[idx, :] = [E0, b, i0, R, iL]\n",
    "\n",
    "                    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebbfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "np.save(f'curves_{n_val}.npy', curves)\n",
    "np.save(f'params_{n_val}.npy', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b05ae",
   "metadata": {},
   "source": [
    "## Dataset separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61afc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance for separation into iL-dataset and no-iL-dataset\n",
    "tol = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367510a",
   "metadata": {},
   "source": [
    "Derivative computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "032e7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = []\n",
    "derivatives_norm = []\n",
    "\n",
    "for idx in range(n_params):\n",
    "    c = curves[idx]\n",
    "    \n",
    "    # Avoid possible NaNs\n",
    "    mask_valid = ~np.isnan(c[:,0]) & ~np.isnan(c[:,1])\n",
    "    i_vals = c[mask_valid, 0]\n",
    "    E_vals = c[mask_valid, 1]\n",
    "    \n",
    "    # Derivative using gradient → same length as i_vals\n",
    "    dE_di = np.gradient(E_vals, i_vals)\n",
    "    derivatives.append((i_vals, dE_di))\n",
    "    \n",
    "    # Current normalization between 0 and 1\n",
    "    i_norm = (i_vals - i_vals.min()) / (i_vals.max() - i_vals.min())\n",
    "    derivatives_norm.append((i_norm, dE_di))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f52edd",
   "metadata": {},
   "source": [
    "Separation through derivative values comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between derivative values\n",
    "mean_second_list = []\n",
    "mean_last_list = []\n",
    "\n",
    "for i_vals, dE_di in derivatives:\n",
    "    n_points = len(dE_di)\n",
    "    \n",
    "    # Mean over the 33%–66% block\n",
    "    start_second = int(n_points * 0.33)\n",
    "    end_second   = int(n_points * 0.66)\n",
    "    mean_second = np.mean(dE_di[start_second:end_second])\n",
    "    \n",
    "    # Mean over the last 3 points\n",
    "    mean_last = np.mean(dE_di[-2:])\n",
    "    \n",
    "    mean_second_list.append(mean_second)\n",
    "    mean_last_list.append(mean_last)\n",
    "\n",
    "dataset_with_iL = []\n",
    "params_with_iL = []\n",
    "dataset_without_iL = []\n",
    "params_without_iL = []\n",
    "\n",
    "for idx in range(n_params):\n",
    "    c = curves[idx]\n",
    "    mean_second = mean_second_list[idx]\n",
    "    mean_last   = mean_last_list[idx]\n",
    "    \n",
    "    if abs(abs(mean_last) - abs(mean_second)) > tol:\n",
    "        if abs(mean_last) > abs(mean_second):\n",
    "            dataset_with_iL.append(c)\n",
    "            params_with_iL.append(params[idx])\n",
    "        else:\n",
    "            dataset_without_iL.append(c)\n",
    "            params_without_iL.append(params[idx])\n",
    "    else:\n",
    "        dataset_without_iL.append(c)\n",
    "        params_without_iL.append(params[idx])\n",
    "\n",
    "dataset_con_iL = np.array(dataset_with_iL, dtype=float)\n",
    "params_con_iL = np.array(params_with_iL, dtype=float)\n",
    "\n",
    "dataset_senza_iL = np.array(dataset_without_iL, dtype=float)\n",
    "params_senza_iL = np.array(params_without_iL, dtype=float)\n",
    "\n",
    "print(f\"Number of curves with iL: {len(dataset_with_iL)}\")\n",
    "print(f\"Number of curves without iL: {len(dataset_without_iL)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3db004",
   "metadata": {},
   "source": [
    "## Saving the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "189e5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'curves_with_iL_{n_val}.npy', dataset_with_iL)\n",
    "np.save(f'params_with_iL_{n_val}.npy', params_with_iL)\n",
    "np.save(f'curves_without_iL_{n_val}.npy', dataset_without_iL)\n",
    "np.save(f'params_without_iL_{n_val}.npy', params_without_iL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
